---
layout: post
title:  "封装H264与AAC为MP4格式"
date:   2021-07-04 14:26:18 +0800
categories: notes
description: "使用MP4V2等工具封装H264与AAC为MP4格式"
author: zburid
tags:   嵌入式 mp4 h264 aac mp4v2 ffmpeg
typora-root-url: ..
show:   true
mermaid: true
---

## 一、音视频格式

### 1、H264

![H264 AVC结构][H.264_AVC_Layer_Structure]

`H.264`分为两层，即**视频编码层**`VCL`（`Video Coding Layer`）和**网络提取层**`NAL`（`Network Abstraction Layer`）。原始视频流在被`VCL`编码、压缩、切分后，再由`NAL`层负责将`VCL`数据打包。


#### 1.1 视频编码层`VCL`

VCL基于混合视频编码，采用了运动补偿预测、变换编码和熵编码等功能，涉及到如下的概念：

* 数据压缩

  当前值`Fn`为输入数据，该值进入编码器后与预测值`P`相减，得到残差`Dn`。`Dn`经过`DCT`变换`T`，量化`Q`后，得到量化系数`X`，再经过重排序，熵编码，生成`SODB`。最后输出到`NAL`，加上解码所需信息，组成`NALU`，形成`h264`码流。

* 场 、帧、图像

  场（`Field`）：隔行扫描的图像，偶数行成为顶场行。奇数行成为底场行。
  帧（`Frame`）：逐行扫描的图像
  图像（`Picture`）：场和帧都可认为是图像.

* 宏块、片

  宏块（`Macroblock`）：一个宏块由一个16×16亮度块、一个8×8Cb和一个8×8Cr组成
  片（`Slice`）：一个图像可以划分成一个或多个片，一个片由一个或多个宏块组成。

* `I`帧

  帧内编码帧（`intra picture`），I 帧通常是每个GOP的第一个帧，经过适度地压缩，做为随机访问的参考点，可以当成图象。I帧可以看成是一个图像经过压缩后的产物。I帧画面完整保留，解码时只需要本帧数据就可以完成（因为包含完整画面）。

* `P`帧

  前向预测编码帧（`predictive-frame`），通过充分将图像序列中前面已编码帧的时间冗余信息来压缩传输数据量的编码图像，也叫预测帧；表示的是这一帧跟之前的一个关键帧（或`P`帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，`P`帧没有完整画面数据，只有与前一帧的画面差别的数据）

* `B`帧

  是双向差别帧（`Bidirectional difference frame`），也就是说`B`帧记录的是本帧与前后帧的差别，换言之，要解码`B`帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。`B`帧压缩率高，但是解码时会占用较多`CPU`资源

* `IDR`帧

  即时解码刷新帧（`Instantaneous Decoding Refresh`），`I`和`IDR`帧都是使用帧内预测的。它们都是同一个东西而已，在编码和解码中为了方便，需要区分首个`I`帧和其他`I`帧，所以才把首个`I`帧叫`IDR`，这样就可以方便控制编码和解码流程


#### 1.2 网络抽象层`NAL`

`NAL`中的数据是由`NALU`（`NAL Unit`）组成的，`NALU`又由`header`和`payload(EBSP)`组成：

![H.264数据流结构][h.264-stream-data-struct]



##### **A. `NALU header`**

`NALU header`总共占用一个字节，用于表示该`NALU`数据的属性：

| 字段               | 位域     | 含义             |
| :----------------- | :------- | :--------------- |
| forbidden_zero_bit | bit[7]   | `NALU`损坏标志   |
| nal_ref_idc        | bit[6,5] | `NALU`相对重要性 |
| nal_unit_type      | bit[4,0] | `NALU`类型       |

* `forbidden_zero_bit`：

  用于检测该`NALU`数据是否在传输过程中发生了**损坏**。为`0`表示数据正常，为`1`表示数据异常，通常该字段为`0`。

* `nal_ref_idc`：

  用于表明该`NALU`数据是否为一个**参考类型**`reference`：参考字段`field`、参考帧`frame`或参考图像`picture`。如果不是参考类型，`nal_ref_idc`值为`0`；否则`nal_ref_idc`值非`0`，表明该`NALU`包含**序列参数集**`SPS`、`SPS`扩展、`SPS`子集、**图像参数集**`PPS`、参考图像切片、参考图像切片数据分区、或者参考图像切片之前的前缀`NALU`。通常该值非`0` 时，数值越大表明该`NALU`数据越重要。

* `nal_unit_type`：

  指定了`NALU`数据体中包含的`RBSP`数据结构类型。`1`到`5`范围的类型值表示`VCL`类型的`NALU`数据，具体的说明如下表中所示，`C`列列出了`NALU`中可能存在的语法元素的类别：

| type  | NALU内容<br/>RBSP语法结构                                    | C     | NALU类型 [Annex A] | NALU类型 [Annex G & H] | NALU类型 [Annex I] |
| ----- | ------------------------------------------------------------ | ----- | ------------------ | ---------------------- | ------------------ |
| 0     | 未指定                                                       |       | non-VCL            | non-VCL                | non-VCL            |
| 1     | 非IDR图像编码切片<br/>slice_layer_without_partitioning_rbsp() | 2/3/4 | VCL                | VCL                    | VCL                |
| 2     | 数据分区A编码切片(DPA)<br/>slice_data_partition_a_layer_rbsp() | 2     | VCL                | NA                     | NA                 |
| 3     | 数据分区B编码切片(DPB)<br/>slice_data_partition_b_layer_rbsp() | 3     | VCL                | NA                     | NA                 |
| 4     | 数据分区C编码切片(DPC)<br/>slice_data_partition_c_layer_rbsp() | 4     | VCL                | NA                     | NA                 |
| 5     | IDR图像编码切片<br/>slice_layer_without_partitioning_rbsp()  | 2/3   | VCL                | VCL                    | VCL                |
| 6     | 补充增强信息(SEI)<br/>sei_rbsp()                             | 5     | non-VCL            | non-VCL                | non-VCL            |
| 7     | 序列参数集(SPS)<br/>seq_parameter_set_rbsp()                 | 0     | non-VCL            | non-VCL                | non-VCL            |
| 8     | 图像参数集(PPS)<br/>pic_parameter_set_rbsp()                 | 1     | non-VCL            | non-VCL                | non-VCL            |
| 9     | AU分割符<br/>access_unit_delimiter_rbsp()                    | 6     | non-VCL            | non-VCL                | non-VCL            |
| 10    | 序列结束符<br/>end_of_seq_rbsp()                             | 7     | non-VCL            | non-VCL                | non-VCL            |
| 11    | 流结束符<br/>end_of_stream_rbsp()                            | 8     | non-VCL            | non-VCL                | non-VCL            |
| 12    | 填充数据<br/>filler_data_rbsp()                              | 9     | non-VCL            | non-VCL                | non-VCL            |
| 13    | SPS扩展<br/>seq_parameter_set_extension_rbsp()               | 10    | non-VCL            | non-VCL                | non-VCL            |
| 14    | 前缀NALU<br/>prefix_nal_unit_rbsp()                          | 2     | non-VCL            | suffix dependent       | suffix dependent   |
| 15    | SPS子集<br/>subset_seq_parameter_set_rbsp()                  | 0     | non-VCL            | non-VCL                | non-VCL            |
| 16~18 | 保留                                                         |       | non-VCL            | non-VCL                | non-VCL            |
| 19    | 无分区辅助编码图像编码切片<br/>slice_layer_without_partitioning_rbsp() | 2/3/4 | non-VCL            | non-VCL                | non-VCL            |
| 20    | 扩展编码切片<br/>slice_layer_extension_rbsp()                | 2/3/4 | non-VCL            | VCL                    | VCL                |
| 21    | 深度视图组件的编码切片扩展<br/>slice_layer_extension_rbsp()<br/>(专用于Annex I) | 2/3/4 | non-VCL            | non-VCL                | VCL                |
| 22~23 | 保留                                                         |       | non-VCL            | non-VCL                | VCL                |
| 24~31 | 未指定                                                       |       | non-VCL            | non-VCL                | non-VCL            |



常见的数据帧类型如下：

* `IDR`帧`Instantaneous Decoder Refresh`：

  **即时解码器刷新**，`I`帧的一种，用于通知解码器，之前依赖的解码参数集合可以被刷新了（接下来要出现的`SPS/PPS`等）。

* `SPS`帧`Sequence Parameter Set`：

  **序列参数集**，保存了一组编码视频序列(Coded Video Sequence)的全局参数，因此该类型保存的是和编码序列相关的参数。

* `PPS`帧`Picture Parameter Set`：

  **图像参数集**，该类型保存了整体图像相关的参数。

* `SEI`帧`Supplemental Enhancement Information`：

  **补充增强信息**，提供了向视频码流中加入额外信息的方法。常用于传递编码器参数、视频版权信息、摄像头参数、或内容生成过程中的剪辑事件（引发场景切换）等信息。

* `AU`分隔符`Access Unit Delimiter`：

  一个或者多个`NALU`的集合，代表了一个完整的帧。`H.264`将构成一帧图像所有`NALU`的集合称为一个`AU`。



##### **B. `NALU payload`**

`NALU payload`通常涉及到三个重要的名词，分别为`EBSP`、`RBSP`和`SODB`。其中`EBSP`完全等价于`NALU payload`，而且它们三个的结构关系为：

```text
+------+     +---------------+     +------------------+         +------+
| SODB |  +  | RBSP Stop bit |  +  | 0 padding bit(s) |   ==>   | RBSP |
+------+     +---------------+     +------------------+         +------+

+-------------+----+-------------+----+-----+-------------+     +------+
| RBSP part 1 |0x03| RBSP part 2 |0x03| ... | RBSP part n | ==> | EBSP |
+-------------+----+-------------+----+-----+-------------+     +------+

+------------------+     +----------------------------+         +------+
|   NALU  header   |  +  |            EBSP            |   ==>   | NALU |
+------------------+     +----------------------------+         +------+
```

* **原始数据比特流** `SODB`：

  `String of Data Bits`，指最原始的`H.264`编码/压缩得到的比特流序列（不包括3～4个字节的`Start Code`）。通常，最左边的位被认为是`MSB`，最右边的位被认为是`LSB`。



* **原始字节序列载荷** `RBSP`：

  `Raw Byte Sequence Payload`，指以字节为单位对齐的数据单元。通常包含0～1个`SODB`数据加上1个`RBSP Stop bit`和0到多个`0 padding bit`。`RBSP Stop bit`长度为`1bit`，`0 padding bit`的作用是使整个`RBSP`以字节为单位对齐。



* **扩展字节序列载荷** `EBSP`：

  `Encapsulate Byte Sequence Payload`，为在数据流中识别出`NALU`的边界，且由于`Start Code`通常为`0x000001/0x00000001`，与`RBSP`中可能存在的`0x00000X`序列相冲突。所以在`RBSP`中每个`0x0000`后面加上一个`0x03`，使其变成`0x0000030X`。



参考文档：

[视频和视频帧：H264编码格式整理][h264-format-note]

[Introduction to H.264: (1) NAL Unit][introduction-to-h264-nal-unit]

[Introduction to H.264: (2) SODB vs RBSP vs EBSP][introduction-to-h264-2-sodb-vs-rbsp-vs-ebsp]

[视频编码（H264概述）](https://www.jianshu.com/p/8422b5e14643)

[h264之路(2)——VCL框架及YCbCr格式](https://www.eefocus.com/guoke1993102/blog/17-06/421205_65ace.html)

[视频中的I、P、B帧](https://blog.csdn.net/qq_37053885/article/details/83539352)

[图像和流媒体 -- I 帧,B帧,P帧,IDR帧的区别](https://blog.csdn.net/qq_29350001/article/details/73770702)




### 2、AAC







### 3、MP4











## 二、MP4V2

### 1、mp4v2移植

#### 1.1、下载源码

可以选择`github`上最新版本的`mp4v2`源码：

```shell
git clone https://github.com/pcwalton/mp4v2.git
```

或者下载常用`2.0.0`版本源码：

```shell
wget https://launchpad.net/ubuntu/+archive/primary/+sourcefiles/mp4v2/2.0.0~dfsg0-6/mp4v2_2.0.0~dfsg0.orig.tar.bz2
tar -xvjf ./mp4v2*.tar.bz2
```

#### 1.2、编译源码

如果没有可执行脚本`configure`可以执行`autoreconf`生成：

```shell
autoreconf -vi
```

配置并编译：

```shell
./configure --host=arm-ca9-linux-gnueabihf CC=arm-ca9-linux-gnueabihf-gcc CXX=arm-ca9-linux-gnueabihf-g++ --disable-debug
make -j12
```

生成需要的文件如下：

```shell
$ tree .
.
├── include
│   └── mp4v2
│       ├── chapter.h
│       ├── file.h
│       ├── file_prop.h
│       ├── general.h
│       ├── isma.h
│       ├── itmf_generic.h
│       ├── itmf_tags.h
│       ├── mp4v2.h
│       ├── platform.h
│       ├── project.h
│       ├── project.h.in
│       ├── sample.h
│       ├── streaming.h
│       ├── track.h
│       └── track_prop.h
└── .lib
    └── libmp4v2.a
```

### 2、mp4v2应用

#### 2.1、API简介

* `MP4Create` 创建文件

```cpp
/** 创建一个新的 mp4 文件
 *
 *  当你想要创建一个新的空白的 mp4 文件，MP4Create 是第一个需要被调用的函数。
 *  它相当于为了写入而打开一个文件，但也涉及到创建必要的 mp4 框架结构。即，调用
 *  MP4Create() 后再调用 MP4Close() 将生成一个非空的文件。
 *
 *  @param fileName 将被创建的文件的 pathname
 *  @param flags 用于允许用户为数据或时间原子设置 64-bit 的 bitmask 。可以是:
 *          @li #MP4_CREATE_64BIT_DATA
 *          @li #MP4_CREATE_64BIT_TIME
 *
 *  @return 成功则返回新创建文件的句柄
 *          失败则引起 #MP4_INVALID_FILE_HANDLE 异常
 */
MP4V2_EXPORT
MP4FileHandle MP4Create(
    const char* fileName,
    uint32_t    flags DEFAULT(0) );
```

* `MP4Close` 关闭文件

```cpp
/** 关闭一个 mp4 文件.
 *  MP4Close 关闭一个之前打开的 mp4 文件。如果该文件被 MP4Create() 或者 
 *  MP4Modify() 以可写方式打开， MP4Close() 将写入所有挂起信息到磁盘中去。
 *
 *  @param hFile 需要关闭文件的句柄.
 *  @param flags 允许用户对关闭命令设置额外选项的 bitmask ，可用的如下:
 *          @li #MP4_CLOSE_DO_NOT_COMPUTE_BITRATE （是否允许在关闭 MP4 文
 *              件前做一些额外的优化处理）
 *  @note 在录制较小的 MP4 文件时可以把 flags 设置为默认值，如果录制较大的文
 *        件最好把 flags 设置为 MP4_CLOSE_DO_NOT_COMPUTE_BITRATE 否则调用
 *        MP4Close 函数会用掉很长的时间。
 */
MP4V2_EXPORT
void MP4Close(
    MP4FileHandle hFile,
    uint32_t    flags DEFAULT(0) );
```

* `MP4SetTimeScale` 设置时间标度

```cpp
/** 设置视频文件的时间标度
 *
 *  MP4SetTimeScale 设置 mp4 文件的时间标度。时间标度是指每秒的时钟滴答个数。
 *  注意：每个轨道可以使用与视频相同的时间标度，也可以使用自己的时间标度。
 *
 *  @param hFile           需要操作文件的句柄
 *  @param value           视频需要的时间标度
 *
 *  @return 成功返回 true ，失败返回 false
 */
MP4V2_EXPORT
bool MP4SetTimeScale( MP4FileHandle hFile, uint32_t value );
```

* `MP4AddAudioTrack` 添加音频轨道

```cpp
/** 添加音频轨道到 mp4 文件.
 *
 *  MP4AddAudioTrack 添加一路音频轨道到 mp4 文件。
 *
 *  推荐设置 timeScale 为音频采样频率如 44100Hz，以便于准确地保留时序信息。
 *
 *  如果音频编码对每个采样使用固定的持续时间，则应在此处指定 sampleDuration 参数。
 *  如果不是，则应为 sampleDuration 参数指定值 #MP4_INVALID_DURATION。
 *
 *  @param hFile           需要操作文件的句柄
 *  @param timeScale       音频轨道每秒的 ticks 数
 *  @param sampleDuration  固定的采样持续时间
 *  @param audioType       音频编码格式
 *      通过 MP4GetTrackEsdsObjectTypeId() 查看支持的类型.
 *
 *  @return 成功则返回新音轨的 track-id
 *          失败则返回 #MP4_INVALID_TRACK_ID.
 */
MP4V2_EXPORT
MP4TrackId MP4AddAudioTrack(
    MP4FileHandle hFile,
    uint32_t      timeScale,
    MP4Duration   sampleDuration,
    uint8_t       audioType DEFAULT(MP4_MPEG4_AUDIO_TYPE) );
```

* `MP4SetTrackESConfiguration` 设置音频解码信息

```cpp
/**
 *  @note mpeg4ip 使用 faac 进行 aac 音频编码的，在编码时可以调用相应的函数得到二进制串
 *        pConfig 和长度 configSize ，但是如果 aac 不是用 faac 编码的，这时需要自己填充 pConfig
 */
MP4V2_EXPORT
bool MP4SetTrackESConfiguration(
    MP4FileHandle  hFile,           /* 需要操作文件的句柄 */
    MP4TrackId     trackId,         /* 需要操作轨道的 id */
    const uint8_t* pConfig,         /* 记录解码信息的二进制流 */
    uint32_t       configSize );    /* 解码串的长度 */
```

* `MP4AddH264VideoTrack` 添加`H264`视频轨道

```cpp
/** 添加一路视频轨道.
 *
 *  MP4AddH264VideoTrack 添加一路视频轨道到 mp4 文件。
 *
 *  推荐设置 timeScale 为 90000 以便针对常用的视频帧速率范围准确地保留时序信息。
 *
 *  如果视频帧速率是固定的，那么 sampleDuration 参数应该给出适当的固定值。
 *  如果视频帧速率是可变的，则应为 sampleDuration 参数指定值 #MP4_INVALID_DURATION
 *
 *  @param hFile           需要操作文件的句柄
 *  @param timeScale       H264视频轨道每秒的 ticks 数（设置为 90000）
 *  @param sampleDuration  固定的采样持续时间（设置为 MP4_INVALID_DURATION）
 *  @param width           帧宽度
 *  @param height          帧高度
 *  @param AVCProfileIndication        sps[1]
 *  @param profile_compat              sps[2]
 *  @param AVCLevelIndication          sps[3]
 *  @param sampleLenFieldSizeMinusOne  设置为 3
 *
 *  @return 成功则返回新轨道的 track-id
 *          失败则返回 #MP4_INVALID_TRACK_ID.
 */
MP4V2_EXPORT
MP4TrackId MP4AddH264VideoTrack(
    MP4FileHandle hFile,
    uint32_t      timeScale,
    MP4Duration   sampleDuration,
    uint16_t      width,
    uint16_t      height,
    uint8_t       AVCProfileIndication,
    uint8_t       profile_compat,
    uint8_t       AVCLevelIndication,
    uint8_t       sampleLenFieldSizeMinusOne );
```

* `MP4SetVideoProfileLevel` 设置视频遵循的协议

```cpp
MP4V2_EXPORT
void MP4SetVideoProfileLevel( MP4FileHandle hFile, uint8_t value );

MP4SetVideoProfileLevel sets the minumum profile/level of MPEG-4 video support necessary to render the contents of the file.

ISO/IEC 14496-1:2001 MPEG-4 Systems defines the following values:
            0x00      Reserved
            0x01      Simple Profile @ Level 3
            0x02      Simple Profile @ Level 2
            0x03      Simple Profile @ Level 1
            0x04      Simple Scalable Profile @ Level 2
            0x05      Simple Scalable Profile @ Level 1
            0x06      Core Profile @ Level 2
            0x07      Core Profile @ Level 1
            0x08      Main Profile @ Level 4
            0x09      Main Profile @ Level 3
            0x0A      Main Profile @ Level 2
            0x0B      N-Bit Profile @ Level 2
            0x0C      Hybrid Profile @ Level 2
            0x0D      Hybrid Profile @ Level 1
            0x0E      Basic Animated Texture @ Level 2
            0x0F      Basic Animated Texture @ Level 1
            0x10      Scalable Texture @ Level 3
            0x11      Scalable Texture @ Level 2
            0x12      Scalable Texture @ Level 1
            0x13      Simple Face Animation @ Level 2
            0x14      Simple Face Animation @ Level 1
            0x15-0x7F Reserved
            0x80-0xFD User private
            0xFE      No audio profile specified
            0xFF      No audio required
```


* `MP4SetAudioProfileLevel` 设置音频遵循的协议

```cpp
MP4V2_EXPORT
void MP4SetAudioProfileLevel( MP4FileHandle hFile, uint8_t value );

MP4SetAudioProfileLevel sets the minumum profile/level of MPEG-4 audio support necessary to render the contents of the file.

ISO/IEC 14496-1:2001 MPEG-4 Systems defines the following values:
            0x00      Reserved
            0x01      Main Profile @ Level 1
            0x02      Main Profile @ Level 2
            0x03      Main Profile @ Level 3
            0x04      Main Profile @ Level 4
            0x05      Scalable Profile @ Level 1
            0x06      Scalable Profile @ Level 2
            0x07      Scalable Profile @ Level 3
            0x08      Scalable Profile @ Level 4
            0x09      Speech Profile @ Level 1
            0x0A      Speech Profile @ Level 2
            0x0B      Synthesis Profile @ Level 1
            0x0C      Synthesis Profile @ Level 2
            0x0D      Synthesis Profile @ Level 3
            0x0E-0x7F Reserved
            0x80-0xFD User private
            0xFE      No audio profile specified
            0xFF      No audio required
```

* `MP4AddH264SequenceParameterSet` 添加序列参数集
* `MP4AddH264PictureParameterSet` 添加图像参数集

```cpp
/**
 *  @note 当检测到序列参数集或图像参数集更新时要调用 MP4AddH264SequenceParameterSet
 *        或 MP4AddH264PictureParameterSet 进行更新
 */
MP4V2_EXPORT
void MP4AddH264SequenceParameterSet(
    MP4FileHandle  hFile,           /* 需要操作文件的句柄 */
    MP4TrackId     trackId,         /* 需要操作轨道的 id */
    const uint8_t* pSequence,       /* 需要写入的序列参数集的数据指针 */
    uint16_t       sequenceLen );   /* 数据长度 */

MP4V2_EXPORT
void MP4AddH264PictureParameterSet(
    MP4FileHandle  hFile,           /* 需要操作文件的句柄 */
    MP4TrackId     trackId,         /* 需要操作轨道的 id */
    const uint8_t* pPict,           /* 需要写入的图像参数集的数据指针 */
    uint16_t       pictLen );       /* 数据长度 */
```

* `MP4WriteSample` 写一帧视频或音频数据

```cpp
/** 写入一个轨道采样.
 *
 *  MP4WriteSample 向指定的轨道末尾写入给定的采样数据。当前的库不支持随机插入采样数据
 *  到轨道时间轴中。需要注意的是，mp4的轨道时间轴中不能有任何空洞或重叠采样数据。最后
 *  三个参数仅供可选的采样信息。
 *
 *  如果轨道中所有的采样都有相同的 duration ，duration 的值可以被设为
 *  #MP4_INVALID_DURATION 。该值可以通过 MP4AddTrack() 和相关函数指定。
 *
 *  对于音频，通常不需要任何可选参数。MPEG音频（如 MP3 或 AAC ）具有固定的采样持续时
 *  间，每个采样都可以随机访问。
 *
 *  对于视频，所有的可选参数可能都需要。通过偶尔的随机访问指针，MPEG 视频能够以一种可
 *  变帧率编码。通过 B 帧，导致显示渲染的的视频帧的顺序与存储解码的顺序不一致。
 *
 *  其他媒体类型介于如上这两种类型之间。
 *
 *  @param hFile           需要操作文件的句柄
 *  @param trackId         需要操作的音视频轨道的 id
 *  @param pBytes          采样数据流的指针
 *  @param numBytes        采样数据流的长度
 *  @param duration        采样持续时间（为前一视频帧与当前视频帧之间的 ticks 数，或
 *                         这是前一段音频数据和当前音频数据之间的 ticks ）
 *  @param renderingOffset 该采样的渲染偏移量（目前唯一需要此功能的媒体类型是MPEG视频）
 *  @param isSyncSample    该采样数据的 同步/随机 访问标志（对视频来说是否为关键帧）
 *
 *  @return 成功返回 true ，失败返回 false
 *
 *  @see MP4AddTrack().
 *  @note   1、duration这个参数是用来实现音视频同步用的，如果设置错了会造成音视频不同步，
 *              甚至会出现 crash 现象（一般出现在调用 MP4Close 时 crash）。 
 *          2、对于视频流 MP4WriteSample 函数每次调用是录制前一帧数据，用当前帧的时间戳
 *          和前一帧的时间戳计算 duration 值，然后把当前帧保存下来用做下次调用 
 *              MP4WriteSample 时用，写音频数据一样。
 */
MP4V2_EXPORT
bool MP4WriteSample(
    MP4FileHandle  hFile,
    MP4TrackId     trackId,
    const uint8_t* pBytes,
    uint32_t       numBytes,
    MP4Duration    duration DEFAULT(MP4_INVALID_DURATION),
    MP4Duration    renderingOffset DEFAULT(0),
    bool           isSyncSample DEFAULT(true) );
```



#### 2.2、测试程序

实现一个简单程序，将`h264`数据与`aac`数据封装为`mp4`文件。参照网上例程，如下：



```cpp
// main.c
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <time.h>
#include <mp4v2/mp4v2.h>



int main(int argc, char** argv)
{
    if (argc != 4) {
        printf("Usage: %s input.h264 input.aac output.mp4\n", argv[0]);
        return -1;
    }
    
}
```





编写`Makefile`文件：

```Makefile
CROSS_COMPILE=/opt/ivot/arm-ca9-linux-gnueabihf-6.5/bin/arm-ca9-linux-gnueabihf-
CC = $(CROSS_COMPILE)cc
TARGETS := mp4v2.out
SRC += main.c
LD_FLAGS +=  -L./lib -lmp4v2 -lstdc++ -lm
C_FLAGS += -Wall -I./include -O2

OBJS = $(SRC:.c=.o)

%.o:%.c
	$(CC) $(C_FLAGS) $(LD_FLAGS) $< -c -o $@

$(TARGETS):$(OBJS)
	$(CC) $(C_FLAGS) -o $@ $< $(LD_FLAGS)
	$(STRIP) $@

clean:
	@rm -f $(TARGETS)
	@rm -f $(OBJS)
```




参考文档：

[使用mp4v2封装mp4][use-mp4v2-pack-h264-to-mp4]

[使用mp4v2将H264和AAC封装mp4][use-mp4v2-pack-h264-aac-to-mp4]

[使用mp4v2封装H.264成mp4最简单示例][mp4v2-pack-h264-to-mp4-example]

[mp4v2接口][mp4v2-api-interface]



## 二、FFMPEG

### 1、ffmpeg移植

```shell
# 下载并编译 x264
git clone https://code.videolan.org/videolan/x264.git
cd ./x264
./configure --prefix=/sdk/convert/ffmpeg/output --enable-static --host=arm-ca9-linux-gnueabihf CC=arm-ca9-linux-gnueabihf-gcc --cross-prefix=arm-ca9-linux-gnueabihf- --disable-asm
make -j12 && make install

# 下载并编译 fdk-aac
git clone https://github.com/mstorsjo/fdk-aac.git
cd fdk-aac && ./autogen.sh
./configure --prefix=/sdk/convert/ffmpeg/output --enable-static --host=arm-ca9-linux-gnueabihf --disable-shared
make -j12 && make install

# 下载并编译SDL2
wget http://www.libsdl.org/release/SDL2-2.0.14.tar.gz
tar -xvzf ./SDL2-2.0.14.tar.gz && cd SDL2-2.0.14
./configure --prefix=/sdk/convert/ffmpeg/output --enable-static --host=arm-ca9-linux-gnueabihf --disable-shared
make -j12 && make install

# 下载并编译 ffmpeg
wget https://ffmpeg.org/releases/ffmpeg-snapshot.tar.bz2
tar -xvjf ./ffmpeg-snapshot.tar.bz2 && cd ffmpeg
./configure --prefix=/sdk/convert/ffmpeg/output --enable-cross-compile --cross-prefix=arm-ca9-linux-gnueabihf- \
--arch=armel --target-os=linux --enable-gpl --enable-nonfree --pkg-config-flags=--static \
--extra-cflags="-I/sdk/convert/ffmpeg/output/include -I/sdk/convert/ffmpeg/output/include/SDL2" \
--extra-ldflags="-L/sdk/convert/ffmpeg/output/lib" --enable-libfdk-aac --enable-libx264 \
--extra-libs="-ldl -fpic -shared -lSDL2" --enable-shared
```

### 2、ffmpeg应用





参考文档：

[arm Linux平台下FFmpeg的移植][porting-ffmpeg-to-arm]

[Ubuntu移植FFmpeg和SDL2][porting-ffmpeg-with-sdl2]







[use-mp4v2-pack-h264-to-mp4]: https://blog.csdn.net/weixin_43549602/article/details/84570642
[use-gpac-pack-h264-to-mp4]: https://blog.csdn.net/weixin_43549602/article/details/84571906
[mp4v2-pack-h264-to-mp4-example]: https://blog.csdn.net/weixin_42462202/article/details/90108485
[use-mp4v2-pack-h264-aac-to-mp4]: https://blog.csdn.net/qq_28581781/article/details/106862139
[mp4v2-api-interface]: https://blog.csdn.net/tgdzsjh/article/details/18044145
[github-mp4v2]: https://github.com/pcwalton/mp4v2

[porting-ffmpeg-with-sdl2]: https://blog.csdn.net/weixin_40285501/article/details/100573320
[porting-ffmpeg-to-arm]: https://blog.csdn.net/horotororensu/article/details/78499709

[h264-format-note]: https://zhuanlan.zhihu.com/p/71928833
[introduction-to-h264-nal-unit]: https://yumichan.net/video-processing/video-compression/introduction-to-h264-nal-unit/
[introduction-to-h264-2-sodb-vs-rbsp-vs-ebsp]: https://yumichan.net/video-processing/video-compression/introduction-to-h264-2-sodb-vs-rbsp-vs-ebsp/
[H.264_AVC_Video_Coding_Standard]: http://iphome.hhi.de/wiegand/assets/pdfs/DIC_H264_07.pdf
[H.264_AVC_Layer_Structure]: /images/H.264_AVC_Layer_Structure.png
[h.264-stream-data-struct]: /images/h.264-stream-data-struct.svg



