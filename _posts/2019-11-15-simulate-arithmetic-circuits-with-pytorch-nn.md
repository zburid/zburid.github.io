---
layout: post
title:  "ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿè¿ç®—ç”µè·¯"
date:   2019-11-15 09:15:34 +0800
categories: notes
description: "ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿè¿ç®—ç”µè·¯ï¼Œé‡‡ç”¨Pytorchå®ç°"
author: zburid
tags:   pytorch ç¥ç»ç½‘ç»œ æ·±åº¦å­¦ä¹  è¿ç®—ç”µè·¯
typora-root-url: ..
show:   true
---
### ä¸€ã€ç®€è¿°
æƒ³è¦å®ç°ä¸€ä¸ªç”±ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿçš„åŠ æ³•å™¨ï¼ˆæˆ–ä¹˜æ³•å™¨æˆ–é™¤æ³•å™¨ï¼‰æ¨¡å‹~~ï¼ˆçœ‹çœ‹æ¦‚ç‡æ¨¡å‹å¦‚ä½•å®ç°é€»è¾‘è¿ç®—ğŸ˜‚ï¼‰~~ã€‚

ä¼—æ‰€å‘¨çŸ¥ï¼Œå®ç°ä¸€ä¸ªç®€å•çš„è¿ç®—å™¨æ—¶éœ€è¦å¾ˆå¤šé€»è¾‘é—¨ï¼ˆä¸æˆ–éï¼‰ï¼Œè€Œæ¯ä¸ªé€»è¾‘é—¨åˆç”±å¤šä¸ª`CMOS`ç”µè·¯ç»„æˆï¼Œå¦‚ä¸‹å°±æ˜¯ä¸€ä¸ª`2bit`åŠ æ³•å™¨çš„`CMOS`ç‰ˆå›¾å®ç°ï¼ŒåŒ…æ‹¬è¿›ä½è¾“å…¥å’Œè¿›ä½è¾“å‡ºï¼š

![2bitåŠ æ³•å™¨][2bit_add_cmos_layout]

ä¸è€ƒè™‘è¶…å‰è¿›ä½çš„è¯ï¼Œåªéœ€è¦å°†å¦‚ä¸Šç‰ˆå›¾å¤åˆ¶`N`ä»½ï¼Œæ¯ä»½çš„è¿›ä½é¦–å°¾ç›¸è¿ï¼Œå°±èƒ½å®ç°ä¸€ä¸ªç®€å•çš„`N`ä½åŠ æ³•å™¨äº†ã€‚

ç„¶è€Œæ­£å¦‚æ‰€çœ‹åˆ°çš„é‚£æ ·ï¼Œç”µè·¯æ˜¯æ•°å­—ç”µè·¯~~ï¼ˆå°±ä¸è€ƒè™‘`CMOS`çš„å¯¼é€šç‰¹æ€§äº†ï¼Œæ‰¯å¤ªè¿œäº†ï¼Œä¹Ÿä¸ä¼šï¼‰~~ï¼Œè¿ç®—æ˜¯æŒ‰ç…§é€»è¾‘è¿›è¡Œçš„ï¼Œè¿™è®©æˆ‘å¥½å¥‡è¿è¡Œç€æµ®ç‚¹æ•°çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œè¯¥å¦‚ä½•æ¨¡æ‹Ÿé€»è¾‘è¿ç®—ã€‚

### äºŒã€æ•°æ®é›†ç”Ÿæˆ

é¦–å…ˆéœ€è¦å¼•å…¥åº“ï¼š

```python
import numpy as np
import random

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.utils.data import Dataset
from torch.utils.data import DataLoader
```

å®ç°æ‰¹é‡æ•°æ®çš„ç”Ÿæˆï¼š

```python
class myDataset(Dataset):
    ''' æ¨¡æ‹Ÿè®¡ç®—ç”µè·¯æ•°æ®ç”Ÿæˆå™¨ï¼Œé»˜è®¤å°ç«¯åœ¨å‰
        Args:
                bitlen: æ€»çº¿ä½å®½
                datalen:æ•°æ®ä¸ªæ•°
                padding:è¾“å…¥æ•°æ®æœ«å°¾å¡«å……0çš„ä¸ªæ•°
                ctype:  è®¡ç®—ç±»å‹
                    'add'   åŠ æ³•è¿ç®—
                    'mul'   ä¹˜æ³•è¿ç®—
                dtype:  æ•°æ®ç»“æ„
                  value           x-dataset              y-dataset(add/mul)
                    0       (datalen, 2*bitlen,)   (datalen, bitlen+1 / 2*bitlen,)
                    1       (datalen, bitlen, 2)   (datalen, bitlen+1 / 2*bitlen,)
                    2       (datalen, 2, bitlen)   (datalen, bitlen+1 / 2*bitlen,)
    '''
    def __init__(self, bitlen, datalen, padding=0, ctype='add', dtype=0):
        if ctype == 'add':
            outbit = bitlen + 1
            calopt = lambda a, b: a + b
        elif ctype == 'mul':
            outbit = bitlen * 2
            calopt = lambda a, b: a * b
        else:
            raise ValueError("Error in ctype:", ctype)

        if dtype == 0:
            megopt = lambda a, b: a + b
        elif dtype == 1:
            megopt = lambda a, b: list(zip(a, b))
        elif dtype == 2:
            megopt = lambda a, b: list(a, b)
        else:
            raise ValueError("Error in dtype:", dtype)

        num2bcd = lambda x, l: [1 & (x >> i) for i in range(l)]
        maxnum = (1 << bitlen) - 1

        if padding > 0:
            bitlen += int(padding)

        inputs, targets = [], []
        for i in range(datalen):
            a, b = random.randint(0, maxnum), random.randint(0, maxnum)
            inputs.append(megopt(num2bcd(a, bitlen), num2bcd(b, bitlen)))
            targets.append(num2bcd(calopt(a, b), outbit))

        self.dsin = np.array(inputs, dtype=np.float32)
        self.dsout = np.array(targets, dtype=np.float32)

    def __len__(self):
        return len(self.dsin)

    def __getitem__(self, idx):
        return (self.dsin[idx], self.dsout[idx])
```

### ä¸‰ã€æ¨¡å‹å®ç°

å…ˆè®¾å®šè¶…å‚æ•°å¦‚ä¸‹ï¼š

```python
bus_width = 32
learning_rate = 1e-3

print_step = 1000
epoches = print_step * 10

batch_size = 64
train_size = batch_size * 50
test_size = batch_size * 4
```

å®ç°ä¸€ä¸ªç®€å•çš„çº¿æ€§ç½‘ç»œï¼š

```python
class Simulator(nn.Module):
    ''' A simulator of arithmetic circuits '''
    def __init__(self, bitlen):
        super(Simulator, self).__init__()
        self.bitlen = bitlen
        self.linear1 = nn.Linear(bitlen*2, bitlen*2)
        self.linear2 = nn.Linear(bitlen*2, bitlen*2)
        self.linear3 = nn.Linear(bitlen*2, bitlen+1)

    def forward(self, x):
        y = self.linear1(x).clamp(min=0)
        y = self.linear2(y).clamp(min=0)
        y = torch.sigmoid(self.linear3(y))
        return y
```

è®­ç»ƒå‡½æ•°ï¼š

```python
def start_train(trainds, testds, model, criterion):
    train_loader = DataLoader(trainds, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(testds, batch_size=test_size, shuffle=True)

    if torch.cuda.is_available():
        model = model.cuda()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    model.train()

    for epoch in range(epoches):
        for inputs, target in train_loader:
            if torch.cuda.is_available():
                inputs = inputs.cuda()
                target = target.cuda()

            outputs = model(inputs)
            loss = criterion(outputs, target)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        if epoch % print_step == print_step - 1:
            for inputs, target in test_loader:
                if torch.cuda.is_available():
                    inputs = inputs.cuda()
                    target = target.cuda()
                rloss = criterion(torch.round(model(inputs)), target)
            print('Epoch{}, loss: {:.6f}, rloss: {:.6f}'.format(
                    epoch, loss.data, rloss.data))
```

å¼€å§‹è®­ç»ƒï¼š

```python
if __name__ == '__main__':
    train_dataset = myDataset(bus_width, train_size)
    test_dataset = myDataset(bus_width, test_size)
    model = Simulator(bus_width)
    start_train(train_dataset, test_dataset, model)
```

è¾“å‡ºç»“æœï¼š

```shell
Epoch999, loss: 0.179174, aloss: 0.435606
Epoch1999, loss: 0.169170, aloss: 0.439394
Epoch2999, loss: 0.168272, aloss: 0.437618
Epoch3999, loss: 0.172583, aloss: 0.439157
Epoch4999, loss: 0.152697, aloss: 0.440341
Epoch5999, loss: 0.169740, aloss: 0.441288
Epoch6999, loss: 0.156561, aloss: 0.441525
Epoch7999, loss: 0.162197, aloss: 0.442590
Epoch8999, loss: 0.160881, aloss: 0.439039
Epoch9999, loss: 0.164809, aloss: 0.442472
```

ç„¶åç»“æœå°±å¾ˆè¿·äº†ï¼Œæ— è®ºæ˜¯ä¿®æ”¹å±‚æ•°ã€ä¿®æ”¹éšå«å±‚ä¸ªæ•°è¿˜æ˜¯æ›´æ”¹`criterion`å‡½æ•°ä¹Ÿå¥½ï¼Œè¾“å‡ºç»“æœå‡ä¸ç†æƒ³ã€‚æ— å¥ˆï¼Œæƒ³èµ·äº†ä¹‹å‰å°è¯•é‡‡ç”¨çš„`TFJS`æ—¶çœ‹åˆ°[åˆ«äººçš„RNNæ–¹æ³•][example_tfjs_rnn_add]ï¼Œå¯ä»¥çœ‹åˆ°è¯¥æ–¹æ³•æ˜¯åŸºäº`NLP`å¤„ç†æ–¹å¼å®ç°çš„ï¼Œä½†ä»ç„¶æ˜¯æœ‰å‚è€ƒæ„ä¹‰ï¼Œé‚ä¿®æ”¹æ¨¡å‹ä¸º`RNN`ï¼š

```python
class SimulatorRNN(nn.Module):
    def __init__(self, hsize=2):
        super(SimulatorRNN, self).__init__()
        self.rnn = nn.RNN(
            input_size = 2,
            hidden_size = hsize,
            num_layers = 1,
            batch_first = True,
            bidirectional = False
        )
        self.linear = nn.Linear(hsize, 1)
    def forward(self, x):
        # x shape   (batch, time_step, input_size=2)
        # out shape (batch, time_step, output_size=1)
        out, _ = self.rnn(x, None)
        out = self.linear(out)
        return torch.squeeze(out)

if __name__ == '__main__':
    train_dataset = myDataset(bus_width, train_size, padding=1, dtype=1)
    test_dataset = myDataset(bus_width, test_size, padding=1, dtype=1)
    model = SimulatorRNN()
    criterion = nn.MSELoss()
    start_train(train_dataset, test_dataset, model, criterion)
```

æ­¤æ—¶ï¼Œè¾“å‡ºç»“æœå°±æ¯”è¾ƒç†æƒ³äº†ï¼š

```shell
Epoch999, loss: 0.084728, aloss: 0.111032
Epoch1999, loss: 0.001671, aloss: 0.000000
Epoch2999, loss: 0.000123, aloss: 0.000000
Epoch3999, loss: 0.000061, aloss: 0.000000
Epoch4999, loss: 0.000045, aloss: 0.000000
Epoch5999, loss: 0.000049, aloss: 0.000000
Epoch6999, loss: 0.000026, aloss: 0.000000
Epoch7999, loss: 0.000032, aloss: 0.000000
Epoch8999, loss: 0.000022, aloss: 0.000000
Epoch9999, loss: 0.000028, aloss: 0.000000
```

### å››ã€è¦ç‚¹æ€»ç»“

#### 1ã€æ¨¡å‹çš„ä¼˜ç¼ºç‚¹

å½“å‰`RNN`æ¨¡å‹çš„è¾“å‡ºç»“æœæ˜¯å…¨éƒ¨`timestep`çš„è¾“å‡ºåºåˆ—ï¼Œæ‰€ä»¥ä¸ºäº†è®¡ç®—åŠ æ³•ï¼Œéœ€è¦å¯¹è¾“å…¥æ•°æ®çš„æœ«å°¾è¡¥é›¶ï¼Œä»¥å®ç°è¾“å…¥å’Œè¾“å‡ºçš„é•¿åº¦ä¸€è‡´ã€‚

ä½†æ˜¯è¿™æ ·ä¹Ÿä¼šå¯¼è‡´äº†æ¨¡å‹åœ¨å®ç°å…¶ä»–åŠŸèƒ½æ—¶å¾€å¾€éœ€è¦æ›´æ”¹ç»“æ„ï¼Œæ¯”å¦‚è®¡ç®—ä¹˜æ³•æ—¶ï¼Œè¾“å‡ºçš„é•¿åº¦æ˜¯è¾“å…¥çš„2å€ï¼Œéœ€è¦å¤šå¯¹å¤šå¤„ç†ã€‚

éªŒè¯è¾“å‡ºæ—¶ï¼Œå¾€å¾€éœ€è¦å°†æ¨¡å‹è¾“å‡ºç»“æœçš„å€¼é™å®šåœ¨`0`å’Œ`1`ä¸¤ä¸ªå€¼ä¸Šï¼Œç„¶è€Œ`Pytorch`å±…ç„¶æ²¡æœ‰é˜¶è·ƒå‡½æ•°$$\varepsilon(x)$$ï¼Œæ‰€ä»¥åªå¥½ä½¿ç”¨å››èˆäº”å…¥`round`å®ç°äº†ï¼ˆåœ¨ç»“æœä¸º`0 ~ 1`é™„è¿‘æœ‰æ•ˆï¼‰ã€‚

#### 2ã€å…¶ä»–é—®é¢˜

`RNN`æ¨¡å‹å¶å°”æ— æ³•æ”¶æ•›ï¼Œæˆ–è€…æ”¶æ•›å¾ˆæ…¢ï¼Œå°¤å…¶æ˜¯`batch_size`è¾ƒå¤§æ—¶ï¼Œç›®å‰è¿˜æ²¡æœ‰å¤´ç»ªã€‚

20191121 - æ”¹ä¸º`LSTM`æˆ–`GRU`å‘ç°æå‡æ•ˆæœæ˜æ˜¾ã€‚


[2bit_add_cmos_layout]: /images/2bit_add_cmos.png
[example_tfjs_rnn_add]: https://orangecsy.github.io/2018/05/22/js-tfjs-5/
